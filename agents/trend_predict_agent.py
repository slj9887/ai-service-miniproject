"""
TrendPredictAgent
ì„ ì •ëœ íŠ¸ë Œë“œì— ëŒ€í•´ í–¥í›„ 3~5ë…„ê°„ ê¸°ìˆ  ë°œì „ ë°©í–¥ê³¼ ì‹œì¥ ì ìš© ê°€ëŠ¥ì„± ì˜ˆì¸¡
"""


import sys, os, json
import re

sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
from agents.state_schema import SystemState

load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini")


def trend_predict_agent(state: SystemState) -> SystemState:
    """TrendAnalysisAgent ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¯¸ë˜ ì „ë§ ìƒì„±"""

    if state is None:
        state = {}

    trend = state.get("current_trend")
    trend_analysis = state.get("trend_analysis")

    if not trend or not trend_analysis:
        print("ë¶„ì„í•  íŠ¸ë Œë“œ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (trend_analysis ì—†ìŒ).")
        return state
    print(f"\n TrendPredictAgent: '{trend}' íŠ¸ë Œë“œì˜ ë¯¸ë˜ ë°œì „ ë°©í–¥ ì˜ˆì¸¡ ì¤‘...")

    context = f"""
    [íŠ¸ëœë“œëª…]
    {trend}

    [íŠ¸ë Œë“œ ë¶„ì„ ìš”ì•½]
    ì •ì˜: {trend_analysis.get('definition')}
    í•µì‹¬ ê¸°ìˆ : {trend_analysis.get('key_technologies')}
    ì‚°ì—… ë™í–¥: {trend_analysis.get('industry_trends')}
    ì ìš© íë¦„: {trend_analysis.get('adoption_flow')}
    ë¯¸ë˜ ì „ë§: {trend_analysis.get('future_outlook')}
    """

    prompt = ChatPromptTemplate.from_template("""
    ë‹¹ì‹ ì€ 2030ë…„ì„ ë‚´ë‹¤ë³´ëŠ” ê¸°ìˆ  ì „ëµ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {trend} ê¸°ìˆ ì˜ ë°œì „ ë°©í–¥, ì‹œì¥ í™•ì¥, ì‚°ì—… ì ìš© ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•˜ì„¸ìš”.
    ì˜ˆì¸¡ì€ ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ê³  2500ì ì •ë„ë¡œ ì‘ì„±í•˜ì„¸ìš”.

    [ë¶„ì„ ì»¨í…ìŠ¤íŠ¸]
    {context}

    ì˜ˆì¸¡ ì‹œ ê³ ë ¤í•  ìš”ì†Œ:
    1. ê¸°ìˆ  ë°œì „ ê²½ë¡œ (ì—°êµ¬/ê°œë°œ ë‹¨ê³„, ì£¼ìš” í˜ì‹  í¬ì¸íŠ¸)
    2. ì‹œì¥ í™•ì¥ ë° íˆ¬ì ì „ë§ (ì˜ˆìƒ CAGR, ì„±ì¥ ìš”ì¸)
    3. ì‚°ì—…ë³„ ì ìš© ê°€ëŠ¥ì„± (ìƒˆë¡œìš´ ì‚°ì—…êµ°, ê¸°ì¡´ ì‚°ì—…ì—ì„œì˜ í™•ì¥ì„±)
    4. ê¸°ìˆ ì /ì •ì±…ì  ì¥ì•  ìš”ì¸
    5. í–¥í›„ 5ë…„ê°„ì˜ ì „ë°˜ì  ì „ë§ ìš”ì•½

    ì¶œë ¥ í˜•ì‹ (JSON):
    {{
      "trend": "{trend}",
      "prediction": {{
        "tech_path": "",
        "market_outlook": "",
        "industry_applications": "",
        "barriers": "",
        "summary": ""
      }}
    }}
                                              
    ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•ì‹ **ê·¸ ìì²´ë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
    ì½”ë“œë¸”ë¡(```)ì´ë‚˜ ë¬¸ì¥, ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    """)

    chain = prompt | llm
    response = chain.invoke({"trend": trend, "context": context})
    raw = response.content.strip()

    def safe_parse_json(raw_text):
        """Markdown, ë¬¸ì¥ ë“±ì´ í¬í•¨ëœ ì‘ë‹µì—ì„œë„ JSONë§Œ ì¶”ì¶œ"""
        try:
            return json.loads(raw_text)
        except Exception:
            # ```json ... ``` ì œê±°
            cleaned = re.sub(r"```(?:json)?|```", "", raw_text, flags=re.DOTALL).strip()
            # JSON ê´„í˜¸ ë‚´ë¶€ë§Œ ì¶”ì¶œ
            cleaned = re.sub(r"^[^{]*({.*})[^}]*$", r"\1", cleaned, flags=re.DOTALL)
            try:
                return json.loads(cleaned)
            except Exception:
                print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨. LLM ì›ë¬¸:", raw_text[:300], "...")
                return None


    result = safe_parse_json(raw)

    # âœ… JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ìƒì„±
    if not result or not isinstance(result, dict):
        print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨. LLM ì‘ë‹µ ì›ë¬¸:\n", raw)
        result = {
            "tech_path": "",
            "market_outlook": "",
            "industry_applications": "",
            "barriers": "",
            "summary": "íŒŒì‹± ì‹¤íŒ¨"
        }

    # âœ… "prediction" í‚¤ê°€ ìˆìœ¼ë©´ ë‚´ë¶€ë¡œ, ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ì‚¬ìš©
    if isinstance(result, dict):
        if "prediction" in result and isinstance(result["prediction"], dict):
            prediction_data = result["prediction"]
        else:
            prediction_data = result
    else:
        prediction_data = {}

    # âœ… ë¹„ì–´ ìˆì„ ê²½ìš° ê¸°ë³¸ê°’ ì œê³µ
    if not prediction_data or not isinstance(prediction_data, dict):
        prediction_data = {
            "tech_path": "",
            "market_outlook": "",
            "industry_applications": "",
            "barriers": "",
            "summary": "LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ"
        }

    # âœ… state ì•ˆì „í•˜ê²Œ ë³µì‚¬ í›„ ì €ì¥
    state = dict(state)
    state["trend_prediction"] = prediction_data

    print("\n TrendPredictAgent ì˜ˆì¸¡ ì™„ë£Œ!\n")
    print(json.dumps(state["trend_prediction"], indent=2, ensure_ascii=False))
    print(f"ğŸ§© [DEBUG] TrendPredictAgent ì¢…ë£Œ ì‹œ state keys: {list(state.keys())}")
    print(f"ğŸ§© [DEBUG] trend_prediction ë‚´ìš© íƒ€ì…: {type(state['trend_prediction'])}, ê°’: {state['trend_prediction']}")
    print(f"[DEBUG] TrendPredictAgent ìµœì¢… ë°˜í™˜ ì§ì „ state keys: {list(state.keys())}")
    print(f"[DEBUG] TrendPredictAgent ìµœì¢… ë°˜í™˜ ì§ì „ trend_prediction: {state.get('trend_prediction')}")


    return state




if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    dummy_state: SystemState = {
        "current_trend": "Federated Learning",
        "trend_analysis": {
            "definition": "ë¶„ì‚° ë°ì´í„° ê¸°ë°˜ í•™ìŠµ ê¸°ìˆ ë¡œ, ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ê°•í™”í•˜ë©´ì„œ í˜‘ì—…í˜• AI í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•¨.",
            "key_technologies": "Differential Privacy, Secure Aggregation, Decentralized Optimization",
            "industry_trends": "í—¬ìŠ¤ì¼€ì–´, ê¸ˆìœµ, IoT ì‚°ì—…ì—ì„œ ë¹ ë¥´ê²Œ ë„ì… ì¤‘",
            "adoption_flow": "ëŒ€ê¸°ì—…ê³¼ ìŠ¤íƒ€íŠ¸ì—… ì¤‘ì‹¬ìœ¼ë¡œ PoC ë° ì´ˆê¸° ìƒìš©í™” ë‹¨ê³„",
            "future_outlook": "ë°ì´í„° ì£¼ê¶Œ ë° ë³´ì•ˆ ì¤‘ì‹¬ì˜ AI ì¸í”„ë¼ë¡œ ì„±ì¥ ì˜ˆìƒ"
        }
    }

    result = trend_predict_agent(dummy_state)
